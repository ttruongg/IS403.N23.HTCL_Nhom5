{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92121fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32d56dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1274.099976</td>\n",
       "      <td>1288.599976</td>\n",
       "      <td>1271.000000</td>\n",
       "      <td>1278.800049</td>\n",
       "      <td>1278.800049</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>1272.500000</td>\n",
       "      <td>1276.099976</td>\n",
       "      <td>1270.300049</td>\n",
       "      <td>1274.300049</td>\n",
       "      <td>1274.300049</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>1275.400024</td>\n",
       "      <td>1275.800049</td>\n",
       "      <td>1260.000000</td>\n",
       "      <td>1261.599976</td>\n",
       "      <td>1261.599976</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>1264.900024</td>\n",
       "      <td>1267.800049</td>\n",
       "      <td>1261.599976</td>\n",
       "      <td>1262.800049</td>\n",
       "      <td>1262.800049</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>1262.300049</td>\n",
       "      <td>1262.400024</td>\n",
       "      <td>1243.900024</td>\n",
       "      <td>1249.800049</td>\n",
       "      <td>1249.800049</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05</th>\n",
       "      <td>1947.500000</td>\n",
       "      <td>1961.900024</td>\n",
       "      <td>1937.800049</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06</th>\n",
       "      <td>1960.800049</td>\n",
       "      <td>1965.500000</td>\n",
       "      <td>1958.800049</td>\n",
       "      <td>1965.500000</td>\n",
       "      <td>1965.500000</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07</th>\n",
       "      <td>1959.000000</td>\n",
       "      <td>1968.400024</td>\n",
       "      <td>1940.699951</td>\n",
       "      <td>1942.699951</td>\n",
       "      <td>1942.699951</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-08</th>\n",
       "      <td>1943.199951</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>1943.099976</td>\n",
       "      <td>1963.599976</td>\n",
       "      <td>1963.599976</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-09</th>\n",
       "      <td>1965.099976</td>\n",
       "      <td>1969.800049</td>\n",
       "      <td>1960.300049</td>\n",
       "      <td>1962.199951</td>\n",
       "      <td>1962.199951</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1390 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2017-12-01  1274.099976  1288.599976  1271.000000  1278.800049  1278.800049   \n",
       "2017-12-04  1272.500000  1276.099976  1270.300049  1274.300049  1274.300049   \n",
       "2017-12-05  1275.400024  1275.800049  1260.000000  1261.599976  1261.599976   \n",
       "2017-12-06  1264.900024  1267.800049  1261.599976  1262.800049  1262.800049   \n",
       "2017-12-07  1262.300049  1262.400024  1243.900024  1249.800049  1249.800049   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2023-06-05  1947.500000  1961.900024  1937.800049  1958.000000  1958.000000   \n",
       "2023-06-06  1960.800049  1965.500000  1958.800049  1965.500000  1965.500000   \n",
       "2023-06-07  1959.000000  1968.400024  1940.699951  1942.699951  1942.699951   \n",
       "2023-06-08  1943.199951  1969.000000  1943.099976  1963.599976  1963.599976   \n",
       "2023-06-09  1965.099976  1969.800049  1960.300049  1962.199951  1962.199951   \n",
       "\n",
       "            Volume  \n",
       "Date                \n",
       "2017-12-01     823  \n",
       "2017-12-04     850  \n",
       "2017-12-05    1499  \n",
       "2017-12-06     373  \n",
       "2017-12-07     358  \n",
       "...            ...  \n",
       "2023-06-05     713  \n",
       "2023-06-06     164  \n",
       "2023-06-07     139  \n",
       "2023-06-08     433  \n",
       "2023-06-09     433  \n",
       "\n",
       "[1390 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = yf.download(tickers = \"GC=F\", start=\"2017-12-01\", end=\"2023-06-10\", interval='1d')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dede5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index('Date', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8211e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Đọc file dữ liệu giá vàng GC=F và chia train test validate theo tỉ lệ 7:2:1\n",
    "data = data[['Close']]\n",
    "data = data.dropna() # Drop missing values\n",
    "data = data.reset_index(drop=True) # Reset the index\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "train_size = int(0.7 * len(data))\n",
    "test_size = int(0.2 * len(data))\n",
    "val_size = len(data) - train_size - test_size\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:train_size+test_size]\n",
    "val_data = data[train_size+test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba987d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Quá trình Training\n",
    "x_train = np.array(train_data.index).reshape(-1, 1)\n",
    "y_train = np.array(train_data['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059ca26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter periodicity is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Python\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter periodicity is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Python\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter periodicity is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 25.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Python\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\", line 324, in fit\n",
      "    self.L_ = cholesky(K, lower=GPR_CHOLESKY_LOWER, check_finite=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: (\"The kernel, DotProduct(sigma_0=1), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '49-th leading minor of the array is not positive definite')\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Python\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py\", line 324, in fit\n",
      "    self.L_ = cholesky(K, lower=GPR_CHOLESKY_LOWER, check_finite=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 89, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Python\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: (\"The kernel, DotProduct(sigma_0=1), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '137-th leading minor of the array is not positive definite')\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Python\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [-703.05301998 -643.08894929   -4.34729921 -594.13476006           nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Kernel: RationalQuadratic(alpha=1, length_scale=1)\n",
      "Best Score: -4.347299211179368\n"
     ]
    }
   ],
   "source": [
    "# Chọn kernel tốt nhất \n",
    "kernels = [RBF(), Matern(), RationalQuadratic(), ExpSineSquared(), DotProduct()]\n",
    "param_grid = {'kernel': kernels}\n",
    "\n",
    "gpr = GaussianProcessRegressor()\n",
    "grid_search = GridSearchCV(gpr, param_grid, cv=KFold(n_splits=5))\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best Kernel:\", grid_search.best_estimator_.kernel)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8febab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo mô hình GPR\n",
    "kernel = RationalQuadratic(alpha=1, length_scale=1)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb1353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianProcessRegressor(kernel=RationalQuadratic(alpha=1, length_scale=1),\n",
       "                         random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianProcessRegressor</label><div class=\"sk-toggleable__content\"><pre>GaussianProcessRegressor(kernel=RationalQuadratic(alpha=1, length_scale=1),\n",
       "                         random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianProcessRegressor(kernel=RationalQuadratic(alpha=1, length_scale=1),\n",
       "                         random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9902356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
